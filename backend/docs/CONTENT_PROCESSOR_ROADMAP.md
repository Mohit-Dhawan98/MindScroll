# Content Processor Architecture Roadmap

## ðŸŽ¯ Vision
Build a comprehensive content processing system that can handle any type of learning material - books, research papers, articles, videos, audio, and more - while leveraging the robust chapter detection and AI-powered card generation system already built for books.

## ðŸ“‹ Current State (Phase 0 - Complete)
- âœ… **Book Processor**: Advanced PDF/EPUB processing with AI-based TOC detection and chapter mapping
- âœ… **Semantic Chunking**: Chapter-aware content chunking with embedding generation
- âœ… **AI Card Generation**: Multi-tier card generation (summaries, flashcards, quizzes)
- âœ… **Bulk Processing**: Parallel book processing with error handling
- âœ… **Dual AI Support**: OpenAI GPT-4.1-mini and Anthropic Claude integration

## ðŸš€ Roadmap Phases

### Phase 1: Content Type Detection & Base Architecture (2-3 weeks)
**Goal**: Create modular architecture that leverages existing book processing infrastructure

#### 1.1 Content Type Detection System
```javascript
// Auto-detect content type from:
- File extensions (.pdf, .epub, .mp3, .mp4, .html)
- URL patterns (youtube.com, arxiv.org, medium.com)
- Content analysis (abstract = paper, chapters = book, timestamps = video)
- MIME types and metadata
```

#### 1.2 Base Processor Architecture
```
processors/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ BaseProcessor.js           // Abstract base class
â”‚   â”œâ”€â”€ ContentTypeDetector.js     // Auto-detection logic
â”‚   â””â”€â”€ ProcessorFactory.js        // Factory pattern for processor creation
â”œâ”€â”€ BookProcessor.js               // Current enhanced system (refactored)
â”œâ”€â”€ ResearchPaperProcessor.js      // Extends BaseProcessor
â”œâ”€â”€ ArticleProcessor.js            // Extends BaseProcessor
â””â”€â”€ VideoProcessor.js              // Extends BaseProcessor
```

### Phase 2: Research Paper Processing (3-4 weeks)
**Goal**: Academic paper processing with citation extraction and section detection

#### 2.1 Research Paper Features
- **Abstract Extraction**: AI-powered abstract identification and summarization
- **Section Detection**: Introduction, Methods, Results, Discussion, Conclusion
- **Citation Processing**: Reference extraction and linking
- **Figure/Table Extraction**: Mathematical formulas and visual content
- **Author/Venue Recognition**: Metadata extraction

#### 2.2 Reuse Book Infrastructure
- âœ… **AI Chapter Detection** â†’ **AI Section Detection**
- âœ… **Semantic Chunking** â†’ **Section-aware Chunking**
- âœ… **Card Generation** â†’ **Academic Card Generation** (terminology, concepts, findings)

### Phase 3: Article & Web Content Processing (2-3 weeks)
**Goal**: Web articles, blog posts, and documentation processing

#### 3.1 Article Features
- **Headline Hierarchy**: H1, H2, H3 structure detection
- **Author/Date Extraction**: Publication metadata
- **Link Processing**: External reference handling
- **Tag/Category Inference**: Content classification

#### 3.2 Reuse Book Infrastructure
- âœ… **Chapter Detection** â†’ **Section Detection** (headlines)
- âœ… **TOC Processing** â†’ **Navigation Menu Processing**
- âœ… **Semantic Chunking** â†’ **Paragraph-based Chunking**

### Phase 4: Video Content Processing (4-5 weeks)
**Goal**: YouTube videos, online courses, and video lectures

#### 4.1 Video Features
- **Transcript Extraction**: YouTube API + Whisper API fallback
- **Timestamp Segmentation**: Chapter markers and topic changes
- **Speaker Identification**: Multiple speaker handling
- **Visual Content**: Slide detection and OCR
- **Auto-Generated Chapters**: AI-based topic segmentation

#### 4.2 Reuse Book Infrastructure
- âœ… **Chapter Detection** â†’ **Segment Detection** (topic changes)
- âœ… **AI Processing** â†’ **Transcript Analysis**
- âœ… **Card Generation** â†’ **Video-based Cards** (concepts, key points, quotes)

### Phase 5: Audio Content Processing (3-4 weeks)
**Goal**: Audiobooks, podcasts, and audio lectures

#### 5.1 Audio Features
- **Speech-to-Text**: Whisper API integration
- **Speaker Diarization**: Multiple speaker identification
- **Chapter Detection**: Audio markers and silence patterns
- **Quality Enhancement**: Noise reduction and normalization

#### 5.2 Reuse Book Infrastructure
- âœ… **Chapter Detection** â†’ **Audio Chapter Detection**
- âœ… **Semantic Processing** â†’ **Transcript Processing**
- âœ… **Card Generation** â†’ **Audio-based Cards**

### Phase 6: Universal Content Processor (2-3 weeks)
**Goal**: Single interface for all content types

#### 6.1 Unified API
```javascript
// Universal content processing
const processor = await ContentProcessorFactory.create(source, options)
const result = await processor.process()

// Auto-detection with override
const result = await processContent(source, { 
  type: 'auto', // or 'book', 'paper', 'article', 'video', 'audio'
  category: 'technology',
  provider: 'openai'
})
```

#### 6.2 Advanced Features
- **Cross-Content Linking**: References between different content types
- **Content Collections**: Group related materials (course modules)
- **Quality Scoring**: Content quality assessment
- **Duplicate Detection**: Avoid processing same content twice

## ðŸ—ï¸ High-Level Design (HLD)

### System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Content Ingestion Layer                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  File Upload  â”‚  URL Fetcher  â”‚  API Integrations  â”‚ Bulk   â”‚
â”‚   (PDF/EPUB)  â”‚  (Web/Video)  â”‚ (YouTube/Academia) â”‚Process â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Content Type Detection Layer                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  File Analysis  â”‚  URL Pattern  â”‚  Content Analysis  â”‚ User â”‚
â”‚  (Extension/MIME) â”‚  Matching   â”‚   (AI-based)      â”‚Overrideâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Processor Selection Layer                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Book      â”‚  Research  â”‚  Article   â”‚  Video   â”‚ Audio   â”‚
â”‚ Processor   â”‚   Paper    â”‚ Processor  â”‚Processor â”‚Processorâ”‚
â”‚             â”‚ Processor  â”‚            â”‚          â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Shared Processing Infrastructure               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Structure   â”‚  AI-Powered â”‚  Semantic  â”‚   Card    â”‚ Vectorâ”‚
â”‚  Detection   â”‚  Analysis   â”‚  Chunking  â”‚Generation â”‚ Store â”‚
â”‚ (TOC/Sectionsâ”‚ (GPT/Claude)â”‚            â”‚           â”‚       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Storage & Retrieval Layer                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Database   â”‚ File Storage â”‚  Cache     â”‚  Vector   â”‚ Indexâ”‚
â”‚  (Metadata)  â”‚ (Content)    â”‚ (Processed)â”‚Embeddings â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Shared Components (Leverage Existing Book Infrastructure)
1. **AI Processing Engine**: Reuse OpenAI/Anthropic integration
2. **Semantic Chunking**: Adapt for different content structures
3. **Card Generation**: Extend existing card types
4. **Vector Store**: Reuse embedding infrastructure
5. **File Storage**: Extend current caching system
6. **Bulk Processing**: Adapt parallel processing framework

## ðŸ”§ Low-Level Design (LLD)

### Base Processor Architecture
```javascript
// Abstract base class
class BaseProcessor {
  constructor(aiProvider = 'openai') {
    this.aiProvider = aiProvider
    this.initialized = false
  }

  // Abstract methods (must be implemented by subclasses)
  async detectStructure(content) { throw new Error('Not implemented') }
  async extractMetadata(content) { throw new Error('Not implemented') }
  async createChunks(structure) { throw new Error('Not implemented') }
  
  // Shared methods (inherited from book processor)
  async generateCards(chunks, metadata) { /* Reuse existing logic */ }
  async buildVectorStore(chunks) { /* Reuse existing logic */ }
  async callAI(prompt) { /* Reuse existing logic */ }
}

// Concrete implementations
class BookProcessor extends BaseProcessor {
  async detectStructure(content) {
    // Existing TOC detection + chapter mapping logic
    return await this.detectBookStructure(content)
  }
}

class ResearchPaperProcessor extends BaseProcessor {
  async detectStructure(content) {
    // Abstract + sections detection (reuse AI detection patterns)
    return await this.detectPaperStructure(content)
  }
}
```

### Content Type Detection
```javascript
class ContentTypeDetector {
  static async detect(source, options = {}) {
    // 1. User override
    if (options.type && options.type !== 'auto') {
      return options.type
    }
    
    // 2. File extension analysis
    const fileType = this.detectFromFile(source)
    if (fileType) return fileType
    
    // 3. URL pattern matching
    const urlType = this.detectFromURL(source)
    if (urlType) return urlType
    
    // 4. AI-based content analysis
    return await this.detectFromContent(source)
  }
  
  static detectFromFile(filePath) {
    const ext = path.extname(filePath).toLowerCase()
    const mapping = {
      '.pdf': this.isPaper(filePath) ? 'paper' : 'book',
      '.epub': 'book',
      '.mp4': 'video',
      '.mp3': 'audio',
      '.html': 'article'
    }
    return mapping[ext]
  }
  
  static detectFromURL(url) {
    const patterns = {
      'youtube.com': 'video',
      'youtu.be': 'video',
      'arxiv.org': 'paper',
      'pubmed.ncbi.nlm.nih.gov': 'paper',
      'medium.com': 'article',
      'dev.to': 'article'
    }
    
    for (const [pattern, type] of Object.entries(patterns)) {
      if (url.includes(pattern)) return type
    }
    return null
  }
}
```

### Processor Factory
```javascript
class ProcessorFactory {
  static async create(contentType, options = {}) {
    const processors = {
      'book': () => new BookProcessor(options.aiProvider),
      'paper': () => new ResearchPaperProcessor(options.aiProvider),
      'article': () => new ArticleProcessor(options.aiProvider),
      'video': () => new VideoProcessor(options.aiProvider),
      'audio': () => new AudioProcessor(options.aiProvider)
    }
    
    const processor = processors[contentType]?.()
    if (!processor) {
      throw new Error(`Unsupported content type: ${contentType}`)
    }
    
    await processor.initialize()
    return processor
  }
}
```

## ðŸ§ª Testing Strategy
1. **Unit Tests**: Each processor type with sample content
2. **Integration Tests**: End-to-end processing workflows
3. **Performance Tests**: Large file processing and parallel execution
4. **Quality Tests**: Card generation quality assessment

## ðŸ“Š Success Metrics
- **Coverage**: Support for 5+ content types
- **Quality**: 90%+ successful processing rate
- **Performance**: <2 minutes average processing time
- **Scalability**: Handle 100+ concurrent processes
- **Reusability**: 80%+ code reuse from book processor

## ðŸ”„ Migration Strategy
1. **Phase 1**: Refactor existing book processor to use base architecture
2. **Phase 2**: Implement new processors one by one
3. **Phase 3**: Gradual rollout with A/B testing
4. **Phase 4**: Full migration and legacy cleanup

## ðŸ“… Timeline
- **Total Duration**: 16-20 weeks
- **Phase 1**: Weeks 1-3 (Architecture)
- **Phase 2**: Weeks 4-7 (Research Papers)
- **Phase 3**: Weeks 8-10 (Articles)
- **Phase 4**: Weeks 11-15 (Video)
- **Phase 5**: Weeks 16-19 (Audio)
- **Phase 6**: Weeks 20 (Universal Interface)

## ðŸš§ Risk Mitigation
- **Content Quality**: Implement validation and quality scoring
- **API Limits**: Rate limiting and quota management
- **Processing Failures**: Robust error handling and retry logic
- **Storage Costs**: Efficient caching and cleanup strategies
- **Performance**: Optimize chunking and embedding generation

This roadmap leverages 80% of the existing book processing infrastructure while adding support for diverse content types. The modular design ensures maintainability and extensibility.

## ðŸŽ“ Learning System Integration

**See**: [Unified Learning System Design](./UNIFIED_LEARNING_SYSTEM_DESIGN.md)

The content processing roadmap is designed to integrate seamlessly with our adaptive learning system:

- **Concept Mapping**: All processors extract learning concepts and structure units
- **Card Generation**: Unified 4-tier card system (FLASHCARD â†’ APPLICATION â†’ QUIZ â†’ SYNTHESIS)
- **Adaptive Routing**: Smart navigation based on user performance and content type
- **Content Flexibility**: Different content types enable different card types and learning flows

### **Content Type Learning Configurations**:
- **Books**: Chapter-based with full 4-tier progression
- **Research Papers**: Section-based with FLASHCARD + QUIZ + SYNTHESIS
- **Articles**: Topic-based with simplified FLASHCARD + QUIZ progression  
- **Videos**: Segment-based with timestamp navigation and 3-tier progression
- **Audio**: Segment-based with transcript sync and concept-focused learning

This ensures consistent learning experiences across all content types while leveraging content-specific features and optimizations.